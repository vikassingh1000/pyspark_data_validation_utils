language: python
jdk: openjdk8
dist: trusty
root: false
cache:
  pip: true
python:
  - "3.6"
before_install:
  - mkdir -p /opt
  - wget -q http://apache.osuosl.org/spark/spark-2.4.7/spark-2.4.7-bin-hadoop2.7.tgz
  - tar xzf spark-2.4.7-bin-hadoop2.7.tgz
  - rm spark-2.4.7-bin-hadoop2.7.tgz
  - pwd
  # Not a good approch, need to fix it to get current working dir and use it
  - export SPARK_HOME=/home/travis/build/vikassingh1000/pyspark_data_validation_utils/spark-2.4.7-bin-hadoop2.7
  - export PATH=$PATH:/home/travis/build/vikassingh1000/pyspark_data_validation_utils/spark-2.4.7-bin-hadoop2.7/bin
  - export PYTHONPATH="$(pwd)"
install:
  - pip install -r requirements.txt
  - pip install -q findspark
  - pip install codecov
  - pip install pytest-cov
script:
  - pytest --cov-report=xml --cov=pyspark_data_validation_utils tests/
after_success:
  - codecov
#after_success:
#  - codecov
